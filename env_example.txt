# HIGH-PERFORMANCE Semantic Database RAG System - Environment Configuration
# Optimized for analyzing 500+ database objects with 5 samples each
# Copy this file to .env and fill in your actual values

# =================================================================
# AZURE OPENAI CONFIGURATION (Required)
# =================================================================
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_ENDPOINT=https://gyp-weu-02-res01-prdenv-cog01.openai.azure.com/
DEPLOYMENT_NAME=gpt-4.1-mini
MODEL_VERSION=2024-12-01-preview

# =================================================================
# DATABASE CONFIGURATION (Required)
# =================================================================
# HIGH-PERFORMANCE SQL Server connection string with optimizations
# Example for SQL Server with Windows Authentication:
DATABASE_CONNECTION_STRING=Driver={ODBC Driver 17 for SQL Server};Server=localhost;Database=YourDatabase;Trusted_Connection=yes;MARS_Connection=yes;MultipleActiveResultSets=true;Pooling=true;Max Pool Size=100;

# Example for SQL Server with SQL Authentication:
# DATABASE_CONNECTION_STRING=Driver={ODBC Driver 17 for SQL Server};Server=localhost;Database=YourDatabase;UID=username;PWD=password;MARS_Connection=yes;MultipleActiveResultSets=true;Pooling=true;Max Pool Size=100;

# Alternative: Individual database connection components
DB_SERVER=localhost
DB_DATABASE=YourDatabase
DB_USERNAME=your_username
DB_PASSWORD=your_password

# =================================================================
# HIGH-PERFORMANCE DISCOVERY CONFIGURATION
# =================================================================

# HIGH-PERFORMANCE Processing (optimized for 500+ objects)
MAX_PARALLEL_WORKERS=16          # Increased from 8 to 16 for faster processing
QUERY_TIMEOUT_SECONDS=20         # Reduced from 30 to 20 for faster failure recovery
MAX_BATCH_SIZE=15               # Increased for better throughput on large datasets
RATE_LIMIT_DELAY=0.1            # Reduced from 0.5 to 0.1 for faster processing

# Sample Data Configuration
SAMPLES_PER_OBJECT=5            # Exactly 5 samples per object as requested
MAX_SAMPLE_ROWS=5               # Maximum 5 rows per object

# Cache settings (optimized for active development)
DISCOVERY_CACHE_HOURS=12        # Shorter cache for active development
SEMANTIC_CACHE_HOURS=24         # 24 hours for semantic analysis

# Database connection timeouts (optimized)
CONNECTION_TIMEOUT=10           # Faster connection timeout
COMMAND_TIMEOUT=20              # Adequate for most queries

# Query processing limits
MAX_RESULTS=100                 # Results per query
USE_FAST_QUERIES=true          # Enable OPTION (FAST n) for 2-5x speed improvement

# =================================================================
# LARGE DATASET OPTIMIZATIONS (New Features)
# =================================================================

# Large Dataset Mode (automatically enabled for 500+ objects)
ENABLE_LARGE_DATASET_MODE=true
LARGE_DATASET_THRESHOLD=100     # Objects count threshold
AGGRESSIVE_PARALLELISM=true     # Use maximum parallelism

# Advanced Performance Features
ENABLE_CONNECTION_POOLING=true
BATCH_COMMIT_SIZE=50
MEMORY_OPTIMIZATION=true

# Filtering Configuration (less aggressive to analyze more objects)
EXCLUDE_BACKUP_TABLES=false     # Changed to false to analyze more objects

# =================================================================
# SYSTEM CONFIGURATION (Optional)
# =================================================================

# Logging configuration
LOG_LEVEL=INFO
LOG_FILE=data/logs/semantic_rag.log
USE_COLORED_LOGS=true

# Semantic analysis settings
CLASSIFICATION_CONFIDENCE_THRESHOLD=0.5
RELATIONSHIP_CONFIDENCE_THRESHOLD=0.6
MAX_RELATIONSHIPS=100

# Query generation settings
SQL_TIMEOUT_SECONDS=30
USE_QUERY_OPTIMIZATION=true
ENABLE_VIEW_PREFERENCE=true

# System behavior
EXCLUDE_SYSTEM_TABLES=true

# =================================================================
# HIGH-PERFORMANCE EXAMPLE CONFIGURATIONS
# =================================================================

# Local SQL Server Express (HIGH-PERFORMANCE):
# DATABASE_CONNECTION_STRING=Driver={ODBC Driver 17 for SQL Server};Server=localhost\SQLEXPRESS;Database=YourDB;Trusted_Connection=yes;MARS_Connection=yes;MultipleActiveResultSets=true;Pooling=true;Max Pool Size=100;

# Azure SQL Database (HIGH-PERFORMANCE):
# DATABASE_CONNECTION_STRING=Driver={ODBC Driver 17 for SQL Server};Server=yourserver.database.windows.net;Database=YourDB;UID=username;PWD=password;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=10;MARS_Connection=yes;MultipleActiveResultSets=true;Pooling=true;Max Pool Size=100;

# SQL Server with custom port (HIGH-PERFORMANCE):
# DATABASE_CONNECTION_STRING=Driver={ODBC Driver 17 for SQL Server};Server=localhost,1433;Database=YourDB;UID=username;PWD=password;MARS_Connection=yes;MultipleActiveResultSets=true;Pooling=true;Max Pool Size=100;

# =================================================================
# PERFORMANCE TUNING FOR 500+ OBJECTS
# =================================================================
# ðŸš€ OPTIMIZED SETTINGS FOR LARGE DATABASES:
# - MAX_PARALLEL_WORKERS=16: Process 16 objects simultaneously
# - SAMPLES_PER_OBJECT=5: Exactly 5 samples as requested
# - USE_FAST_QUERIES=true: 2-5x speed improvement with OPTION (FAST n)
# - EXCLUDE_BACKUP_TABLES=false: Analyze more objects (less filtering)
# - RATE_LIMIT_DELAY=0.1: Minimal delay between operations
# - ENABLE_LARGE_DATASET_MODE=true: Automatic optimizations
# - Connection pooling: Reuse connections for better performance

# ðŸ“Š EXPECTED PERFORMANCE:
# - 500 objects: ~15-20 minutes
# - 1000 objects: ~25-35 minutes  
# - Each object gets exactly 5 sample rows
# - Views are now fully supported (previous versions showed 0)
# - Minimal filtering keeps business-relevant objects

# ðŸ’¡ PERFORMANCE TIPS:
# - Run during off-peak hours for large databases
# - Monitor system resources (CPU, memory)
# - Results are cached for faster subsequent runs
# - Greek/Unicode text is automatically supported
# - Views and tables are processed equally

# =================================================================
# TROUBLESHOOTING HIGH-PERFORMANCE MODE
# =================================================================
# If you encounter issues with large datasets:
# 1. Reduce MAX_PARALLEL_WORKERS to 8 if system is overloaded
# 2. Increase QUERY_TIMEOUT_SECONDS if complex views time out
# 3. Set ENABLE_LARGE_DATASET_MODE=false for smaller databases
# 4. Check database connection limits and increase if needed
# 5. Monitor memory usage and reduce BATCH_COMMIT_SIZE if needed

# Performance monitoring:
# - Watch CPU usage during discovery
# - Monitor database connection count
# - Check for timeout errors in logs
# - Verify cache file sizes (should be 10-50MB for large datasets)

# =================================================================
# WHAT'S NEW IN HIGH-PERFORMANCE VERSION
# =================================================================
# âœ… MAJOR IMPROVEMENTS:
# - Removed artificial limits (TOP 200 tables, TOP 100 views)
# - Now analyzes ALL 500+ objects in database
# - Exactly 5 samples per object (previously 3)
# - Views now fully supported (previously 0 views analyzed) 
# - Minimal filtering (keeps business objects previously excluded)
# - 2x faster with increased parallelism (16 workers vs 8)
# - FAST query option for 2-5x speed improvement
# - Large dataset mode with automatic optimizations
# - Better Unicode/Greek text support
# - Connection pooling for better performance
# - Progress tracking and time estimation
# - Enhanced error handling and recovery